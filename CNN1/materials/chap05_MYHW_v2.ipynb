{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今Lessonで学んだことを元に、MNISTのファッション版 (Fashion MNIST、クラス数10) を多層パーセプトロンによって分類してみましょう。\n",
    "\n",
    "Fashion MNISTの詳細については以下のリンクを参考にしてください。\n",
    "\n",
    "Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ルール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **下のセルで指定されている`x_train`、`y_train`以外の学習データは使わないでください。**\n",
    "- MLPの実装には`tf`の低レベルAPIのみを用いてください。具体的に以下のモジュールは使用しないでください。\n",
    "```python\n",
    "tf.app,\n",
    "tf.compat,\n",
    "tf.contrib,\n",
    "tf.estimator,\n",
    "tf.gfile,\n",
    "tf.graph_util,\n",
    "tf.image,\n",
    "tf.initializers,\n",
    "tf.keras,\n",
    "tf.layers,\n",
    "tf.logging,\n",
    "tf.losses,\n",
    "tf.metrics,\n",
    "tf.python_io,\n",
    "tf.resource_loader,\n",
    "tf.saved_model,\n",
    "tf.sets,\n",
    "tf.summary,\n",
    "tf.sysconfig,\n",
    "tf.test,\n",
    "tf.train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出方法\n",
    "- 2つのファイルを提出していただきます。\n",
    "    1. テストデータ (`x_test`) に対する予測ラベルを`submission_pred.csv`として保存し、**Homeworkタブから`chap05`を選択して**提出してください。\n",
    "    2. それに対応するpythonのコードを`submission_code.py`として保存し、**Homeworkタブから`chap05 (code)`を選択して**提出してください。\n",
    "      - セルに書いたコードを.py形式で保存するためには%%writefileコマンドなどを利用してください（writefileコマンドではファイルの保存のみが行われセル内のpythonコード自体は実行されません。そのため、実際にコードを走らせる際にはwritefileコマンドをコメントアウトしてください）。\n",
    "      \n",
    "- なお、採点は1で行い、2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）。コードの内容を変更した場合は、**1と2の両方を提出し直してください**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 予測ラベルの`y_test`に対する精度 (Accuracy) で評価します.\n",
    "- 毎日夜24時にテストデータの一部に対する精度でLeader Boardを更新します.\n",
    "- 締切日の夜24時にテストデータ全体に対する精度でLeader Boardを更新します. これを最終的な評価とします."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み\n",
    "- この部分は修正しないでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrequired modules are already deleted (Skipped).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    del [\n",
    "        tf.app,\n",
    "        tf.compat,\n",
    "        tf.contrib,\n",
    "        tf.estimator,\n",
    "        tf.gfile,\n",
    "        tf.graph_util,\n",
    "        tf.image,\n",
    "        tf.initializers,\n",
    "        tf.keras,\n",
    "        tf.layers,\n",
    "        tf.logging,\n",
    "        tf.losses,\n",
    "        tf.metrics,\n",
    "        tf.python_io,\n",
    "        tf.resource_loader,\n",
    "        tf.saved_model,\n",
    "        tf.sets,\n",
    "        tf.summary,\n",
    "        tf.sysconfig,\n",
    "        tf.test,\n",
    "        tf.train\n",
    "    ]\n",
    "except AttributeError:\n",
    "    print('Unrequired modules are already deleted (Skipped).')\n",
    "\n",
    "def load_fashionmnist():\n",
    "    # 学習データ\n",
    "    x_train = np.load('/root/userspace/public/chap05/data/x_train.npy')\n",
    "    y_train = np.load('/root/userspace/public/chap05/data/y_train.npy')\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('/root/userspace/public/chap05/data/x_test.npy')\n",
    "    \n",
    "    x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
    "    y_train = np.eye(10)[y_train.astype('int32')]\n",
    "    x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
    "    \n",
    "    return x_train, y_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多層パーセプトロンの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層とDropout層からなるMLPを実装します。\n",
    "\n",
    "順伝播の式を示します。\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf u}^{(1)} &= {\\bf W}^{(1)\\mathrm{T}} {\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "    {\\bf h}^{(1)} &= \\mathrm{ReLU}({\\bf u}^{(1)}) \\\\\n",
    "    {\\bf \\tilde{h}}^{(1)} &= \\mathrm{Dropout}({\\bf h}^{(1)}) \\\\\n",
    "    {\\bf u}^{(2)} &= {\\bf W}^{(2)\\mathrm{T}} {\\bf \\tilde{h}}^{(1)} + {\\bf b}^{(2)} \\\\\n",
    "    {\\bf h}^{(2)} &= \\mathrm{ReLU}({\\bf u}^{(2)}) \\\\\n",
    "    {\\bf \\tilde{h}}^{(2)} &= \\mathrm{Dropout}({\\bf h}^{(2)}) \\\\\n",
    "    {\\bf u}^{(3)} &= {\\bf W}^{(3)\\mathrm{T}} {\\bf \\tilde{h}}^{(2)} + {\\bf b}^{(3)} \\\\\n",
    "    {\\bf y} &= \\mathrm{softmax} ({\\bf u}^{(3)})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorboard' has no attribute 'show_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-68af2e1f2afb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard' has no attribute 'show_graph'"
     ]
    }
   ],
   "source": [
    "import tensorboard as tb\n",
    "tb.show_graph(sess.graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /root/userspace/chap05/submission/submission_code_result3.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile /root/userspace/chap05/submission/submission_code_result3.py\n",
    "\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "x_train, t_train, x_test = load_fashionmnist()\n",
    "\n",
    "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=1000)\n",
    "\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "#                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "# print(tf.shape(x_train))\n",
    "# plt.figure()\n",
    "# plt.imshow(x_train[0])\n",
    "# plt.colorbar()\n",
    "# plt.grid(False)\n",
    "# plt.show()\n",
    "x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "x_valid = (x_valid.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "\n",
    "print(tf.shape(t_train))\n",
    "# t_train = np.eye(10)[t_train].astype(np.float32)\n",
    "# t_valid = np.eye(10)[t_valid].astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# 以下Model記述に専念する部分\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) #入力データ\n",
    "t = tf.placeholder(tf.float32, [None, 10]) #出力データ\n",
    "is_training = tf.placeholder(tf.bool) #訓練中の信号\n",
    "\n",
    "Time = tf.Variable(1.0, name ='Time')\n",
    "\n",
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function = lambda x: x):\n",
    "        self.W = tf.Variable(tf.random_uniform(shape = [in_dim, out_dim], minval = -0.08, maxval = 0.08), name = 'W')\n",
    "        self.b = tf.Variable(tf.zeros(shape = out_dim), name = 'b')\n",
    "        \n",
    "        self.function = function\n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, dropout_keep_prob = 1.0):\n",
    "        self.dropout_keep_prob = dropout_keep_prob\n",
    "        self.params = []\n",
    "        \n",
    "    def __call__(self, h):\n",
    "        return tf.cond(\n",
    "            pred = is_training, #訓練時に限定する\n",
    "            # lambda式の引数は今回は指定しないということっぽいな?\n",
    "            true_fn = lambda : tf.nn.dropout(h, keep_prob = self.dropout_keep_prob),\n",
    "            false_fn = lambda : h\n",
    "        )\n",
    "\n",
    "# tf.log(0)によるnanを防ぐ\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))    \n",
    "\n",
    "def compute_l1_reg(params):\n",
    "    l1_reg = 0\n",
    "    for param in params:\n",
    "        l1_reg += tf.reduce_sum(tf.abs(param))\n",
    "    return l1_reg\n",
    "\n",
    "def compute_l2_reg(params):\n",
    "    l2_reg = 0\n",
    "    for param in params:\n",
    "        shape_param = tf.shape(param)\n",
    "        l2_reg += tf.reduce_sum(tf.pow(param,tf.fill(shape_param,2.0)))\n",
    "    return l2_reg\n",
    "\n",
    "def sgd(cost, params, eps=0.1):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for grad, param in zip(grads, params):\n",
    "        updates.append(param.assign_sub(eps*grad))\n",
    "    return updates\n",
    "\n",
    "def rmsprop(cost, params, eta=0.001, rho=0.9, eps=1e-7):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        G = tf.Variable(tf.zeros_like(param, dtype = tf.float32), name = 'G')\n",
    "        updates.append(G.assign(rho * G + (1 - rho) * (grad**2)))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub((eta/tf.sqrt(G + eps))*grad))\n",
    "    return updates\n",
    "\n",
    "# def rmsprop(cost, params, eta=0.001, rho=0.9, eps=1e-7):\n",
    "#     grads = tf.gradients(cost, params)\n",
    "#     updates = []\n",
    "#     for param, grad in zip(params, grads):\n",
    "#         G = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='G')\n",
    "#         updates.append(G.assign(rho * G + (1 - rho) * grad**2))\n",
    "#         with tf.control_dependencies(updates):\n",
    "#             updates.append(param.assign_sub(eta / tf.sqrt(G + eps) * grad))\n",
    "#     return updates\n",
    "\n",
    "def momentum(cost, params, eta = 0.01, gamma = 0.9):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for grad, param in zip(grads, params):\n",
    "        v = tf.Variable(tf.zeros_like(param, dtype = tf.float32), name = 'v')\n",
    "        updates.append(v.assign(eta*grad + gamma*v))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(v))\n",
    "    return updates\n",
    "\n",
    "\n",
    "def adagrad(cost, params, eta=0.01, eps=1e-7):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        G = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='G')\n",
    "        updates.append(G.assign_add(grad**2))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(eta / tf.sqrt(G + eps) * grad))\n",
    "    return updates\n",
    "\n",
    "# 自分で書いてみたAdam\n",
    "# notationはGoodfellow参照した\n",
    "def Adam(cost, params, t, eps = 0.001, rho_1 = 0.9, rho_2 = 0.999, delta = 1e-8):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for grad, param in zip(grads, params):\n",
    "        s = tf.Variable(tf.zeros_like(param, dtype = tf.float32), name = 's') # バイアス付１次モーメント初期化\n",
    "        r = tf.Variable(tf.zeros_like(param, dtype = tf.float32), name = 'r') # バイアス付2次モーメント初期化\n",
    "        updates.append(s.assign(rho_1 * s + (1 - rho_1) * grad))\n",
    "        updates.append(r.assign(rho_2 * r + (1 - rho_2) * (grad**2)))\n",
    "        s_hat = s/(1 - rho_1 ** t)\n",
    "        r_hat = r/(1 - rho_2 ** t)\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub((eps * s_hat)/tf.sqrt(r_hat + delta)))\n",
    "    return updates\n",
    "\n",
    "\n",
    "\n",
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 100 # バッチサイズ\n",
    "n_epochs = 200 # epoch数\n",
    "\n",
    "\n",
    "\n",
    "layers = [\n",
    "    Dense(784, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.params\n",
    "        params_all.extend(params)\n",
    "    return params_all\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "\n",
    "y = f_props(layers, x)\n",
    "params_all = get_params(layers)\n",
    "# l2_reg = compute_l2_reg(params_all)\n",
    "# l1_reg = compute_l1_reg(params_all)\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) #+ lmd * l1_reg\n",
    "\n",
    "# updates = rmsprop(cost, params_all, eta)\n",
    "updates = Adam(cost=cost, params = params_all, t = Time)\n",
    "train = tf.group(*updates)\n",
    "\n",
    "n_batches = math.ceil(len(x_train) / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        x_train, t_train = shuffle(x_train, t_train)\n",
    "        Time = 1\n",
    "        for i in range(n_batches):\n",
    "            Time = Time + 1\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
    "        y_pred, cost_valid_ = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
    "        if ((epoch+1)%10 == 0):\n",
    "            print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "                epoch + 1,\n",
    "                cost_valid_,\n",
    "                accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "            ))\n",
    "    y_pred = sess.run(y, feed_dict = {x: x_test, is_training: False})\n",
    "    y_pred = y_pred.argmax(axis = 1)\n",
    "    submission = pd.Series(y_pred, name='label')\n",
    "    submission.to_csv('/root/userspace/chap05/submission/submission_pred_result3.csv', header=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 1:\n",
    "Adam is used as optimization algorithm.  \n",
    "784 -> 128 -> D -> 128 -> D -> 10  \n",
    "```python\n",
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 100 # バッチサイズ\n",
    "n_epochs = 100 # epoch数\n",
    "\n",
    "```\n",
    "EPOCH: 10, Valid Cost: 0.593, Valid Accuracy: 0.783  \n",
    "EPOCH: 20, Valid Cost: 0.502, Valid Accuracy: 0.823  \n",
    "EPOCH: 30, Valid Cost: 0.461, Valid Accuracy: 0.848  \n",
    "EPOCH: 40, Valid Cost: 0.433, Valid Accuracy: 0.858  \n",
    "EPOCH: 50, Valid Cost: 0.416, Valid Accuracy: 0.860  \n",
    "EPOCH: 60, Valid Cost: 0.401, Valid Accuracy: 0.862  \n",
    "EPOCH: 70, Valid Cost: 0.386, Valid Accuracy: 0.870  \n",
    "EPOCH: 80, Valid Cost: 0.378, Valid Accuracy: 0.870  \n",
    "EPOCH: 90, Valid Cost: 0.369, Valid Accuracy: 0.870  \n",
    "EPOCH: 100, Valid Cost: 0.372, Valid Accuracy: 0.875  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 2:\n",
    "Adam is used as optimization algorithm.  \n",
    "784 -> 200 -> D -> 200 -> D -> 10  \n",
    "```python\n",
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 100 # バッチサイズ\n",
    "n_epochs = 100 # epoch数\n",
    "\n",
    "```\n",
    "EPOCH: 10, Valid Cost: 0.564, Valid Accuracy: 0.791  \n",
    "EPOCH: 20, Valid Cost: 0.481, Valid Accuracy: 0.819  \n",
    "EPOCH: 30, Valid Cost: 0.444, Valid Accuracy: 0.828  \n",
    "EPOCH: 40, Valid Cost: 0.413, Valid Accuracy: 0.846  \n",
    "EPOCH: 50, Valid Cost: 0.395, Valid Accuracy: 0.853  \n",
    "EPOCH: 60, Valid Cost: 0.381, Valid Accuracy: 0.861  \n",
    "EPOCH: 70, Valid Cost: 0.373, Valid Accuracy: 0.868  \n",
    "EPOCH: 80, Valid Cost: 0.357, Valid Accuracy: 0.877  \n",
    "EPOCH: 90, Valid Cost: 0.355, Valid Accuracy: 0.879  \n",
    "EPOCH: 100, Valid Cost: 0.351, Valid Accuracy: 0.878  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 3:\n",
    "Adam is used as optimization algorithm.  \n",
    "784 -> 200 -> D -> 200 -> D -> 200 -> D -> 10  \n",
    "```python\n",
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 100 # バッチサイズ\n",
    "n_epochs = 200 # epoch数\n",
    "\n",
    "```\n",
    "EPOCH: 10, Valid Cost: 0.546, Valid Accuracy: 0.790  \n",
    "EPOCH: 20, Valid Cost: 0.465, Valid Accuracy: 0.823  \n",
    "EPOCH: 30, Valid Cost: 0.427, Valid Accuracy: 0.831  \n",
    "EPOCH: 40, Valid Cost: 0.406, Valid Accuracy: 0.838  \n",
    "EPOCH: 50, Valid Cost: 0.387, Valid Accuracy: 0.852  \n",
    "EPOCH: 60, Valid Cost: 0.364, Valid Accuracy: 0.862  \n",
    "EPOCH: 70, Valid Cost: 0.360, Valid Accuracy: 0.872  \n",
    "EPOCH: 80, Valid Cost: 0.352, Valid Accuracy: 0.872  \n",
    "EPOCH: 90, Valid Cost: 0.347, Valid Accuracy: 0.874  \n",
    "EPOCH: 100, Valid Cost: 0.352, Valid Accuracy: 0.867  \n",
    "EPOCH: 110, Valid Cost: 0.338, Valid Accuracy: 0.878  \n",
    "EPOCH: 120, Valid Cost: 0.345, Valid Accuracy: 0.871  \n",
    "EPOCH: 130, Valid Cost: 0.332, Valid Accuracy: 0.875  \n",
    "EPOCH: 140, Valid Cost: 0.340, Valid Accuracy: 0.879  \n",
    "EPOCH: 150, Valid Cost: 0.327, Valid Accuracy: 0.887  \n",
    "EPOCH: 160, Valid Cost: 0.333, Valid Accuracy: 0.876  \n",
    "EPOCH: 170, Valid Cost: 0.331, Valid Accuracy: 0.880  \n",
    "EPOCH: 180, Valid Cost: 0.333, Valid Accuracy: 0.886  \n",
    "EPOCH: 190, Valid Cost: 0.339, Valid Accuracy: 0.889  \n",
    "EPOCH: 200, Valid Cost: 0.342, Valid Accuracy: 0.878  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = sess.run([y], feed_dict = {x: x_test, is_training: False})\n",
    "# submission = pd.Series(y_pred, name='label')\n",
    "# submission.to_csv('/root/userspace/chap05/submission/submission_pred.csv', header=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 23 16:53:11 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla M60           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   45C    P0    37W / 150W |    250MiB /  7618MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorboard' has no attribute 'show_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a30cabe4ff97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' nvidia-smi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# np.shape(x_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# x_train_img = x_train.reshape(-1,28,28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plt.figure()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard' has no attribute 'show_graph'"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "tb.show_graph(sess.graph) \n",
    "# np.shape(x_train)\n",
    "# x_train_img = x_train.reshape(-1,28,28)\n",
    "# plt.figure()\n",
    "# plt.imshow(x_train_img[0])\n",
    "# plt.colorbar()\n",
    "# plt.grid(False)\n",
    "# plt.show()\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "#                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "# plt.figure(figsize=(10,10))\n",
    "# for i in range(25):\n",
    "#     plt.subplot(5,5,i+1)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.grid(False)\n",
    "#     plt.imshow(x_train_img[i], cmap=plt.cm.binary)\n",
    "#     plt.xlabel(class_names[t_train[i,:].argmax()])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったオペレーション\n",
    "# tf.get_default_graph().get_operations()\n",
    "# 今までの実行によりデフォルトグラフ上に溜まったVariables\n",
    "# tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Valid Cost: 2.717, Valid Accuracy: 0.181\n",
      "EPOCH: 2, Valid Cost: 2.708, Valid Accuracy: 0.181\n",
      "EPOCH: 3, Valid Cost: 2.698, Valid Accuracy: 0.085\n",
      "EPOCH: 4, Valid Cost: 2.689, Valid Accuracy: 0.085\n",
      "EPOCH: 5, Valid Cost: 2.680, Valid Accuracy: 0.085\n",
      "EPOCH: 6, Valid Cost: 2.671, Valid Accuracy: 0.085\n",
      "EPOCH: 7, Valid Cost: 2.663, Valid Accuracy: 0.085\n",
      "EPOCH: 8, Valid Cost: 2.654, Valid Accuracy: 0.085\n",
      "EPOCH: 9, Valid Cost: 2.646, Valid Accuracy: 0.086\n",
      "EPOCH: 10, Valid Cost: 2.638, Valid Accuracy: 0.124\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorboard' has no attribute 'show_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77b33a41803a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         ))\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 単純な足し算のグラフの表示 (がしたいが...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard' has no attribute 'show_graph'"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        x_train, t_train = shuffle(x_train, t_train)\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
    "        y_pred, cost_valid_ = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
    "        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "            epoch + 1,\n",
    "            cost_valid_,\n",
    "            accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.Series(y_pred, name='label')\n",
    "submission.to_csv('/root/userspace/chap05/submission/submission_pred.csv', header=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
